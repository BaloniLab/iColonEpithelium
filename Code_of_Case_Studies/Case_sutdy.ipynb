{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import xlsxwriter\n",
    "from adjustText import adjust_text\n",
    "import cobra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from itertools import permutations, product, combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from cobra.io import read_sbml_model, write_sbml_model, save_matlab_model, load_matlab_model\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "from time import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GUROBI_HOME'] = \"/depot/pbaloni/data/Lab_members/Boyu_Jiang/Software/gurobi_license\"\n",
    "os.environ['GRB_LICENSE_FILE'] = \"/depot/pbaloni/data/Lab_members/Boyu_Jiang/Software/gurobi_license/gurobi.lic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UC sutdy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run FVA with context-specific reconstructions of healthy samples in the UC study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UC healthy\n",
    "\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Healthy_reconstructions/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Healthy_reconstructions/'\n",
    "for i in files_path:\n",
    "    model_path = folder + i\n",
    "    print(model_path)\n",
    "    model = cobra.io.load_matlab_model(model_path)\n",
    "    model.objective = ['ACSm', 'FACOAL40im', 'BIOMASS_maintenance']\n",
    "    model.solver = 'cplex'\n",
    "    print(model.objective.expression)\n",
    "    fva_output = flux_variability_analysis(model)\n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FVA_outputs/'\n",
    "    file_name = i.split('.mat')[0]\n",
    "    save_path = save_path + file_name + '.csv'\n",
    "    fva_output.to_csv(save_path)\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UC inflammatory\n",
    "# Run fva with context-specific reconstructions of inflammatory samples in the UC study\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Inflamed_reconstructions/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Inflamed_reconstructions/'\n",
    "for i in files_path:\n",
    "    model_path = folder + i\n",
    "    print(model_path)\n",
    "    model = cobra.io.load_matlab_model(model_path)\n",
    "    model.objective = ['ACSm', 'FACOAL40im', 'BIOMASS_maintenance']\n",
    "    model.solver = 'cplex'\n",
    "    print(model.objective.expression)\n",
    "    fva_output = flux_variability_analysis(model)\n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FVA_outputs/'\n",
    "    file_name = i.split('.mat')[0]\n",
    "    save_path = save_path + file_name + '.csv'\n",
    "    fva_output.to_csv(save_path)\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge maximum flux of the FVA outputs above\n",
    "all_rxn = []\n",
    "length = 1\n",
    "\n",
    "for filename in os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FAV_output'):\n",
    "    print(filename)    \n",
    "    filePath = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FAV_output/' + filename\n",
    "    fva = pd.read_csv(filePath)\n",
    "    rxn = fva.iloc[:,0].to_list()\n",
    "    length += len(rxn)\n",
    "    all_rxn += rxn\n",
    "print(length)\n",
    "print(len(all_rxn))\n",
    "reaction_deduplicated = list(set(all_rxn))\n",
    "\n",
    "print(\"merge fVA values--------------------\")\n",
    "# merge all fva maximum value\n",
    "workbook =xlsxwriter.Workbook('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/Results_analysis/FVA_mergedAll.xlsx', {\"nan_inf_to_errors\": True})\n",
    "sheet = workbook.add_worksheet()\n",
    "for i in range(len(reaction_deduplicated)):\n",
    "    reaction = reaction_deduplicated[i]\n",
    "    sheet.write(i+1, 0, reaction)\n",
    "\n",
    "index = 1\n",
    "file_list = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FAV_output/')\n",
    "for filename in sorted(file_list):\n",
    "    print(filename)\n",
    "    sample_name = filename[:-8]\n",
    "    filePath = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FAV_output/' + filename\n",
    "    sheet.write(0,index, sample_name)\n",
    "    \n",
    "\n",
    "    fva = pd.read_csv(filePath, index_col=0)\n",
    "    fva_rxn = fva.index.to_list()\n",
    "    for i in range(len(reaction_deduplicated)):\n",
    "        reaction = reaction_deduplicated[i]\n",
    "        if reaction in fva_rxn:\n",
    "            value = fva.loc[reaction, 'maximum']\n",
    "            sheet.write(i+1, index, value)\n",
    "        else:\n",
    "            value = None\n",
    "            sheet.write(i+1, index, value)\n",
    "    index += 1\n",
    "\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UC T-test \n",
    "UC_data = pd.read_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/Results_analysis/FVA_mergedAll.xlsx', index_col=0)\n",
    "\n",
    "\n",
    "p_val = []\n",
    "for i in range(4817):\n",
    "    rxn_id = UC_data.index[i]\n",
    "    rxn_fluxes = UC_data.loc[rxn_id].tolist()\n",
    "    ifla_flux = rxn_fluxes[0:3]\n",
    "    ht_flux  = rxn_fluxes[3:]\n",
    "    try:\n",
    "        t_statistic, p_value = ttest_ind(ifla_flux, ht_flux)\n",
    "        p_val.append(p_value)\n",
    "    except:\n",
    "        p_val.append(np.nan)\n",
    "\n",
    "UC_data['p_value'] = p_val\n",
    "UC_data.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/Results_analysis/UC_t_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Flux sampling with all context-specific reconstructions in the UC study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UC_folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/'\n",
    "\n",
    "for i in ['Healthy_reconstructions', 'Inflamed_reconstructions']:\n",
    "    folder =  UC_folder + i\n",
    "    print(folder)\n",
    "    file_names = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    print(file_names)\n",
    "\n",
    "    for i in range(len(file_names)):\n",
    "        print(i)\n",
    "        filename  = file_names[i]\n",
    "        print(filename)\n",
    "        file_path = folder + '/' + filename\n",
    "        model = load_matlab_model(file_path)\n",
    "        # model.objective = ['ACSm', 'FACOAL40im', 'BIOMASS_maintenance']\n",
    "        try:\n",
    "            achr = ACHRSampler(model, thinning=10)\n",
    "            s1 = achr.sample(1000)\n",
    "            save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/UC/'\n",
    "            save_file_name = filename.split('.xml')[0]\n",
    "            save_file = save_path + save_file_name + '.csv'\n",
    "            s1.to_csv(save_file)\n",
    "        except:\n",
    "            print('cannnot obtain sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_lists_to_same_length(data, pad_value=np.nan):\n",
    "    max_length = max(len(lst) for lst in data.values())\n",
    "    for key, lst in data.items():\n",
    "        if len(lst) < max_length:\n",
    "            data[key].extend([pad_value] * (max_length - len(lst)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined fluxes from each group of UC\n",
    "UC_flux_files = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/UC')\n",
    "UC_flux_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/UC/'\n",
    "\n",
    "# UC_inflamed \n",
    "inflam_dict = {}\n",
    "for i in UC_flux_files:\n",
    "    if i.startswith('Inflame'):\n",
    "        file_path = UC_flux_path + '/' + i\n",
    "        fluxes_data = pd.read_csv(file_path, index_col=0)\n",
    "        rxn_list = fluxes_data.columns.to_list()\n",
    "        for i in rxn_list:\n",
    "            rxn = i\n",
    "            rxn_flux = fluxes_data[rxn].to_list()\n",
    "            if rxn not in inflam_dict.keys():\n",
    "                inflam_dict[rxn] = rxn_flux\n",
    "            else:\n",
    "                ori_flux = inflam_dict[rxn]\n",
    "                combined_flux = ori_flux + rxn_flux\n",
    "                inflam_dict[rxn] = combined_flux\n",
    "        inflam_dict = pad_lists_to_same_length(inflam_dict)\n",
    "df_inflam = pd.DataFrame(inflam_dict)\n",
    "df_inflam.to_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_inflam_combined.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "health_dict = {}\n",
    "for i in UC_flux_files:\n",
    "    if i.startswith('Health'):\n",
    "        file_path = UC_flux_path + '/' + i\n",
    "        fluxes_data = pd.read_csv(file_path, index_col=0)\n",
    "        rxn_list = fluxes_data.columns.to_list()\n",
    "        for i in rxn_list:\n",
    "            rxn = i\n",
    "            rxn_flux = fluxes_data[rxn].to_list()\n",
    "            if rxn not in health_dict.keys():\n",
    "                health_dict[rxn] = rxn_flux\n",
    "            else:\n",
    "                ori_flux = health_dict[rxn]\n",
    "                combined_flux = ori_flux + rxn_flux\n",
    "                health_dict[rxn] = combined_flux\n",
    "        health_dict = pad_lists_to_same_length(health_dict)\n",
    "df_HT = pd.DataFrame(health_dict)\n",
    "df_HT.to_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_HT_combined.csv')\n",
    "\n",
    "\n",
    "\n",
    "UC_inflammation = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_inflam_combined.csv', index_col=0)\n",
    "UC_health = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_HT_combined.csv', index_col=0)\n",
    "\n",
    "workbook = xlsxwriter.Workbook('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_combinedFlux_comparsion.xlsx')\n",
    "sheet1 = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "sheet1.write(0, 0, 'UC_inflammation_vs_health')\n",
    "sheet1.write(1, 0, 'Reactions')\n",
    "sheet1.write(1, 1, 'Subsystem')\n",
    "sheet1.write(1, 2, 'Flux_CD')\n",
    "sheet1.write(1, 3, 'Flux_HT')\n",
    "sheet1.write(1, 4, 'P-value')\n",
    "inflam_rxns = UC_inflammation.columns.to_list()\n",
    "health_rxns = UC_health.columns.to_list()\n",
    "overlapped_rxn = list(set(inflam_rxns).intersection(health_rxns))\n",
    "\n",
    "row_index = 2\n",
    "for rxn in overlapped_rxn:\n",
    "    print(rxn)\n",
    "    sheet1.write(row_index, 0, rxn)\n",
    "    \n",
    "    inflam_fluxes = UC_inflammation[rxn].to_list()\n",
    "    inflam_fluxes = [x for x in inflam_fluxes if not math.isnan(x)]\n",
    "    health_fluxes = UC_health[rxn].to_list()\n",
    "    health_fluxes = [x for x in health_fluxes if not math.isnan(x)]\n",
    "    inflam_fluxes_mean = mean(inflam_fluxes)\n",
    "    health_fluxes_mean = mean(health_fluxes)\n",
    "    sheet1.write(row_index, 2, inflam_fluxes_mean)\n",
    "    sheet1.write(row_index, 3, health_fluxes_mean)\n",
    "    t_statistic, p_value = ttest_ind(inflam_fluxes, health_fluxes)\n",
    "    sheet1.write(row_index, 4, p_value)\n",
    "    row_index +=1\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build combined flux distribution plot of UC\n",
    "metabolic_tasks = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/input_metabolic_tasks.csv')\n",
    "metabolic_tasks = metabolic_tasks['Reaction_Recon3D'].to_list()\n",
    "UC_inflam_fluxes = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_inflam_combined.csv', index_col=0)\n",
    "UC_health_fluxes = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/UC_HT_combined.csv', index_col=0)\n",
    "\n",
    "\n",
    "save_folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/DistributionPlots/'\n",
    "\n",
    "for i in metabolic_tasks:\n",
    "    reaction = i\n",
    "\n",
    "    try:\n",
    "        UC_inflam_data = UC_inflam_fluxes[reaction].to_list()\n",
    "        UC_inflam_data = [x for x in UC_inflam_data if not math.isnan(x)]\n",
    "        UC_health_data = UC_health_fluxes[reaction].to_list()\n",
    "        UC_health_data = [x for x in UC_health_data if not math.isnan(x)]\n",
    "\n",
    "        # Sample data\n",
    "        data1 = UC_inflam_data\n",
    "        data2 = UC_health_data\n",
    "\n",
    "        # Create distribution plot for data1 and data2\n",
    "        sns.histplot(data1, kde=True, color='red', label='Inflammatory group', alpha=0.5)\n",
    "        sns.histplot(data2, kde=True, color='blue', label='Healthy group', alpha=0.5)\n",
    "\n",
    "        plt.xlabel('Flux value (mmol/gDW/h)')\n",
    "        plt.ylabel('Density')\n",
    "        Plot_title = 'UC study: ' + reaction\n",
    "        plt.title(Plot_title)\n",
    "        plt.legend()\n",
    "        save_path = save_folder + 'UC_' + reaction + '.png'\n",
    "        plt.savefig(save_path,dpi=600)\n",
    "        plt.show()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single gene knockout simulation in UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icolon = read_sbml_model('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Draft_reconstructions/Draft_reconstruction_consensus/icolonoEpithelium.xml')\n",
    "reactions_all = ['BIOMASS_maintenance', 'ACSm', 'FACOAL40im', \n",
    "                 'HACD1m',\n",
    "                 'ECOAH1m',\n",
    "                 '5HOXINDACTOX',\n",
    "                 'ECOAH1x',\n",
    "                 'HACD1x',\n",
    "                 '3HKYNAKGAT',\n",
    "                 '5HOXINOXDA',\n",
    "                 'RE2349C',\n",
    "                 'r0647',\n",
    "                 'ACACT1m']\n",
    "\n",
    "merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "merged_df.index = merged_df['reaction_id']\n",
    "\n",
    "\n",
    "\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Healthy_reconstructions/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Healthy_reconstructions/'\n",
    "print(files_path)\n",
    "\n",
    "for i in range(len(files_path)):\n",
    "    print(i)\n",
    "    file_name = files_path[i]\n",
    "    print(file_name)\n",
    "    merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "    merged_df.index = merged_df['reaction_id']\n",
    "    \n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/' + file_name + '_knock.xlsx'\n",
    "\n",
    "    \n",
    "    \n",
    "    model_path = folder + file_name\n",
    "    model = load_matlab_model(model_path)\n",
    "    model.solver = 'cplex'\n",
    "    print(i)\n",
    "    index = 0\n",
    "    reaction = [i.id for i in model.reactions]\n",
    "    reactions_all_filter = list(set(reactions_all)&set(reaction))\n",
    "    for i in model.genes:\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        index +=1 \n",
    "        gene_id = i.id\n",
    "        \n",
    "        model_copy = model.copy()\n",
    "        model_copy.genes.get_by_id(gene_id).knock_out()\n",
    "        fva = flux_variability_analysis(model_copy, reactions_all_filter, processes = 9)\n",
    "        fva = fva.drop(columns=['minimum'])\n",
    "        fva.rename(columns={'maximum': gene_id}, inplace=True)\n",
    "        merged_df = pd.merge(merged_df,fva, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "    merged_df.to_excel(save_path)\n",
    "    print('complete knockout:', file_name)\n",
    "\n",
    "\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Inflamed_reconstructions/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/model_imat_samples/Inflamed_reconstructions/'\n",
    "print(files_path)\n",
    "\n",
    "for i in range(len(files_path)):\n",
    "    print(i)\n",
    "    file_name = files_path[i]\n",
    "    print(file_name)\n",
    "    merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "    merged_df.index = merged_df['reaction_id']\n",
    "    \n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/' + file_name + '_knock.xlsx'\n",
    "\n",
    "    \n",
    "    model_path = folder + file_name\n",
    "    model = load_matlab_model(model_path)\n",
    "    reaction = [i.id for i in model.reactions]\n",
    "    reactions_all_filter = list(set(reactions_all)&set(reaction))\n",
    "    model.solver = 'cplex'\n",
    "\n",
    "    index = 0\n",
    "    for i in model.genes:\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        index +=1 \n",
    "        gene_id = i.id\n",
    "        \n",
    "        model_copy = model.copy()\n",
    "        model_copy.genes.get_by_id(gene_id).knock_out()\n",
    "        fva = flux_variability_analysis(model_copy, reactions_all_filter, processes = 6)\n",
    "        fva = fva.drop(columns=['minimum'])\n",
    "        fva.rename(columns={'maximum': gene_id}, inplace=True)\n",
    "        merged_df = pd.merge(merged_df,fva, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "    merged_df.to_excel(save_path)\n",
    "    print('knockout completed:', file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "reactions_all = [i.id for i in icolon.genes]\n",
    "merged_df = pd.DataFrame({'': reactions_all})\n",
    "merged_df.index = merged_df['']\n",
    "                             \n",
    "merged_biomass = merged_df['']\n",
    "merged_acsm = merged_df['']\n",
    "merge_FACOAL40im = merged_df['']\n",
    "merge_ACACT1m = merged_df['']\n",
    "merge_ECOAH1m = merged_df['']\n",
    "merge_5HOXINOXDA = merged_df['']\n",
    "merge_5HOXINDACTOX = merged_df['']\n",
    "merge_3HKYNAKGAT = merged_df['']\n",
    "\n",
    "\n",
    "files = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/'\n",
    "files.remove('processed')\n",
    "files.remove('plot_dada')\n",
    "files.remove('Figure')\n",
    "\n",
    "files.sort()\n",
    "\n",
    "for i in files:\n",
    "    print(i)\n",
    "    sample_id = i.split('.mat_knock.xlsx')[0]\n",
    "    print(sample_id)\n",
    "    file_path = folder + i\n",
    "    df_ko = pd.read_excel(file_path)\n",
    "    df_ko.index = df_ko['reaction_id']\n",
    "\n",
    "    selected_rxn = ['BIOMASS_maintenance', \n",
    "                    'ACSm', \n",
    "                    'FACOAL40im', \n",
    "                    'ACACT1m', \n",
    "                    'ECOAH1m', \n",
    "                    '5HOXINOXDA', \n",
    "                    '5HOXINDACTOX', \n",
    "                    '3HKYNAKGAT']\n",
    "\n",
    "    df_ko = df_ko.loc[selected_rxn]\n",
    "    \n",
    "\n",
    "    col1 = sample_id + '_BIOMASS_maintenance'\n",
    "    col2 = sample_id + '_ACSm'\n",
    "    col3 = sample_id + '_FACOAL40im'\n",
    "    col4 = sample_id + '_ACACT1m'\n",
    "    col5 = sample_id + '_ECOAH1m'\n",
    "    col6 = sample_id + '_5HOXINOXDA'\n",
    "    col7 = sample_id + '_5HOXINDACTOX'\n",
    "    col8 = sample_id + '_3HKYNAKGAT'\n",
    "\n",
    "    df_ko_t = df_ko.T\n",
    "    df_ko_t.columns =[col1, col2, col3, col4, col5, col6, col7, col8]\n",
    "    df_ko_t = df_ko_t.iloc[2:]\n",
    "\n",
    "\n",
    "    wt_df_folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Broad_study/FAV_per_sample/FAV_outputs_0521_2024_lu_0/'\n",
    "    wt_df_folder_path = wt_df_folder  + sample_id + '.csv'\n",
    "    wt_df = pd.read_csv(wt_df_folder_path, index_col=0)\n",
    "   \n",
    "    wt_BIOMASS = wt_df.loc['BIOMASS_maintenance', 'maximum']\n",
    "    if wt_BIOMASS == 0:\n",
    "        wt_BIOMASS = 1e-8\n",
    "        print('set wt_BIOMASS as 1e-8')\n",
    "    else:\n",
    "        print(wt_BIOMASS)\n",
    "\n",
    "    wt_acsm = wt_df.loc['ACSm', 'maximum']\n",
    "    if wt_acsm == 0:\n",
    "        wt_acsm = 1e-8\n",
    "        print('set wt_acsm as 1e-8')\n",
    "    else:\n",
    "        print(wt_acsm)\n",
    "   \n",
    "    wt_FACOAL40im = wt_df.loc['FACOAL40im', 'maximum']\n",
    "    if wt_FACOAL40im == 0:\n",
    "        wt_FACOAL40im = 1e-8\n",
    "        print('set wt_FACOAL40im as 1e-8')\n",
    "    else:\n",
    "        print(wt_FACOAL40im)\n",
    "\n",
    "    try:\n",
    "        wt_ACACT1m = wt_df.loc['ACACT1m', 'maximum']\n",
    "        if wt_ACACT1m == 0:\n",
    "            wt_ACACT1m = 1e-8\n",
    "            print('set wt_ACACT1m as 1e-8')\n",
    "        else:\n",
    "            print(wt_ACACT1m)\n",
    "    except:\n",
    "        wt_ACACT1m = 1e-8\n",
    "        print('set wt_ACACT1m as 1e-8')\n",
    "\n",
    "    try:\n",
    "        wt_ECOAH1m = wt_df.loc['ECOAH1m', 'maximum']\n",
    "        if wt_ECOAH1m == 0:\n",
    "            wt_ECOAH1m = 1e-8\n",
    "            print('set wt_ECOAH1m as 1e-8')\n",
    "        else:\n",
    "            print(wt_ECOAH1m)\n",
    "    except:\n",
    "        wt_ECOAH1m = 1e-8\n",
    "        print('set wt_ECOAH1m as 1e-8')\n",
    "\n",
    "\n",
    "    try:\n",
    "        wt_5HOXINDACTOX = wt_df.loc['5HOXINDACTOX', 'maximum']\n",
    "        if wt_5HOXINDACTOX == 0:\n",
    "            wt_5HOXINDACTOX = 1e-8\n",
    "            print('set wt_5HOXINDACTOX as 1e-8')\n",
    "        else:\n",
    "            print(wt_5HOXINDACTOX)\n",
    "    except:\n",
    "        wt_5HOXINDACTOX = 1e-8\n",
    "        print('set wt_5HOXINDACTOX as 1e-8')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        wt_5HOXINOXDA = wt_df.loc['5HOXINOXDA', 'maximum']\n",
    "        if wt_5HOXINOXDA == 0:\n",
    "            wt_5HOXINOXDA = 1e-8\n",
    "            print('set wt_5HOXINOXDA as 1e-8')\n",
    "        else:\n",
    "            print(wt_5HOXINOXDA)\n",
    "    except:\n",
    "        wt_5HOXINOXDA = 1e-8\n",
    "        print('set wt_5HOXINOXDA as 1e-8')\n",
    "\n",
    "\n",
    "    try:\n",
    "        wt_3HKYNAKGAT = wt_df.loc['3HKYNAKGAT', 'maximum']\n",
    "        if wt_3HKYNAKGAT == 0:\n",
    "            wt_3HKYNAKGAT = 1e-8\n",
    "            print('set wt_3HKYNAKGAT as 1e-8')\n",
    "        else:\n",
    "            print(wt_3HKYNAKGAT)\n",
    "    except:\n",
    "        wt_3HKYNAKGAT = 1e-8\n",
    "        print('set wt_3HKYNAKGAT as 1e-8')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    BIOMASS = df_ko_t.iloc[:, 0:1]\n",
    "    BIOMASS = (wt_BIOMASS-BIOMASS)/wt_BIOMASS\n",
    "    merged_biomass = pd.merge(merged_biomass, BIOMASS, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    acsm = df_ko_t.iloc[:, 1:2]\n",
    "    acsm = (wt_acsm-acsm)/wt_acsm\n",
    "    merged_acsm = pd.merge(merged_acsm, acsm, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    FACOAL40im = df_ko_t.iloc[:, 2:3]\n",
    "    FACOAL40im = (wt_FACOAL40im-FACOAL40im)/wt_FACOAL40im\n",
    "    merge_FACOAL40im = pd.merge(merge_FACOAL40im, FACOAL40im, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    ACACT1m = df_ko_t.iloc[:, 3:4]\n",
    "    ACACT1m = (wt_ACACT1m-ACACT1m)/wt_ACACT1m\n",
    "    merge_ACACT1m = pd.merge(merge_ACACT1m, ACACT1m, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    ECOAH1m = df_ko_t.iloc[:, 4:5]\n",
    "    ECOAH1m = (wt_ECOAH1m-ECOAH1m)/wt_ECOAH1m\n",
    "    merge_ECOAH1m = pd.merge(merge_ECOAH1m, ECOAH1m, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    _5HOXINOXDA = df_ko_t.iloc[:, 5:6]\n",
    "    _5HOXINOXDA = (wt_5HOXINOXDA-_5HOXINOXDA)/wt_5HOXINOXDA\n",
    "    merge_5HOXINOXDA = pd.merge(merge_5HOXINOXDA, _5HOXINOXDA, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    _5HOXINDACTOX = df_ko_t.iloc[:, 6:7]\n",
    "    _5HOXINDACTOX = (wt_5HOXINDACTOX-_5HOXINDACTOX)/wt_5HOXINDACTOX\n",
    "    merge_5HOXINDACTOX = pd.merge(merge_5HOXINDACTOX, _5HOXINDACTOX, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    _3HKYNAKGAT = df_ko_t.iloc[:, 7:8]\n",
    "    _3HKYNAKGAT = (wt_3HKYNAKGAT-_3HKYNAKGAT)/wt_3HKYNAKGAT\n",
    "    merge_3HKYNAKGAT = pd.merge(merge_3HKYNAKGAT, _3HKYNAKGAT, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    \n",
    "\n",
    "merged_biomass = merged_biomass.drop(merged_biomass.columns[0], axis=1)\n",
    "merged_acsm = merged_acsm.drop(merged_acsm.columns[0], axis=1)\n",
    "merge_FACOAL40im = merge_FACOAL40im.drop(merge_FACOAL40im.columns[0], axis=1)\n",
    "merge_ACACT1m = merge_ACACT1m.drop(merge_ACACT1m.columns[0], axis=1)\n",
    "merge_ECOAH1m = merge_ECOAH1m.drop(merge_ECOAH1m.columns[0], axis=1)\n",
    "merge_5HOXINOXDA = merge_5HOXINOXDA.drop(merge_5HOXINOXDA.columns[0], axis=1)\n",
    "merge_5HOXINDACTOX = merge_5HOXINDACTOX.drop(merge_5HOXINDACTOX.columns[0], axis=1)\n",
    "merge_3HKYNAKGAT = merge_3HKYNAKGAT.drop(merge_3HKYNAKGAT.columns[0], axis=1)   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "merged_biomass.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_BIOMASS.xlsx')\n",
    "\n",
    "merged_acsm.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_ACSm.xlsx')\n",
    "\n",
    "merge_FACOAL40im.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_FACOAL40im.xlsx')\n",
    "\n",
    "merge_ACACT1m.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_ACACT1m.xlsx')\n",
    "\n",
    "merge_ECOAH1m.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_ECOAH1m.xlsx')\n",
    "\n",
    "merge_5HOXINOXDA.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_5HOXINOXDA.xlsx')\n",
    "\n",
    "merge_5HOXINDACTOX.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_5HOXINDACTOX.xlsx')\n",
    "\n",
    "merge_3HKYNAKGAT.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/UC_3HKYNAKGAT.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/processed/'\n",
    "files = os.listdir(folder)\n",
    "\n",
    "for i in files:\n",
    "    file_path = folder + i\n",
    "    print(i)\n",
    "    df = pd.read_excel(file_path, index_col=0)\n",
    "    df.sort_values(by=df.columns.tolist(), ascending=True, inplace=True)\n",
    "    cd_mean  = df.iloc[:, :3].mean(axis=1)\n",
    "    ht_mean  = df.iloc[:, 3:7].mean(axis=1)\n",
    "    all_mean = df.iloc[:, 0:7].mean(axis=1)\n",
    "    ratio = abs(cd_mean/ht_mean)\n",
    "    try:\n",
    "        ratio_log2 = ratio.apply(lambda x: math.log2(x))\n",
    "    except:\n",
    "        #cd_mean  = df.iloc[:, :3].mean(axis=1)\n",
    "        #cd_mean = cd_mean.replace(0, 1e-8)\n",
    "        #ht_mean  = df.iloc[:, 3:7].mean(axis=1)\n",
    "        #all_mean = df.iloc[:, 0:7].mean(axis=1)\n",
    "        #ratio = abs(cd_mean/ht_mean)\n",
    "        #ratio_log2 = ratio.apply(lambda x: math.log2(x))\n",
    "        continue\n",
    "    ratio_log2 = ratio_log2.to_frame()\n",
    "    \n",
    "    # t-test\n",
    "    cd = df.iloc[:, :3]\n",
    "    ht = df.iloc[:, 3:7]\n",
    "    t_statistic, p_values = ttest_ind(cd, ht, axis=1, nan_policy='omit')\n",
    "\n",
    "    geneID = cd.index\n",
    "    geneID = geneID.to_list()\n",
    "    p_values = list(p_values)\n",
    "    ttest_results = pd.DataFrame({'GeneID':geneID, 'p-valve': p_values})\n",
    "    ttest_results.index = ttest_results['GeneID']\n",
    "    ttest_results = ttest_results.drop('GeneID', axis=1)\n",
    "    \n",
    "    ratio_log2.rename(columns={ratio_log2.columns[0]: 'log2(CD/WT)'}, inplace=True)\n",
    "    ratio_log2['all mean'] = all_mean\n",
    "    volcano_data = pd.merge(ratio_log2, ttest_results, left_index=True, right_index=True, how='left')\n",
    "    volcanoPlot_data_save = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/plot_dada/' + i\n",
    "    print(volcanoPlot_data_save)\n",
    "    volcano_data.to_excel(volcanoPlot_data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build volcano plot \n",
    "volcano_data = pd.read_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/plot_dada/UC_BIOMASS.xlsx', index_col=0)\n",
    "\n",
    "log_fold_change = volcano_data['log2(CD/WT)']\n",
    "p_values = volcano_data['p-valve']\n",
    "p_values = -np.log10(p_values)\n",
    "all_mean = volcano_data['all mean']\n",
    "gene_id = volcano_data.index.to_list()\n",
    "threshold = -np.log10(0.05)\n",
    "\n",
    "sizes = np.linspace(1, 250, len(all_mean))\n",
    "colors = ['red' if fc > 0 else 'blue' for fc in log_fold_change]\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=900)\n",
    "plt.scatter(log_fold_change, p_values, s=sizes, c=colors, alpha=0.5)\n",
    "\n",
    "text = []\n",
    "font_props = {'family': 'monospace', 'size': 8, 'weight': 'bold'}\n",
    "for x, y, l in zip(log_fold_change, p_values, gene_id):\n",
    "    if y > -np.log10(0.05):\n",
    "        text.append(plt.text(x, y, l, size=10, ha='center', va='center', fontdict=font_props))\n",
    "\n",
    "adjust_text(text, expand=(2, 5),arrowprops=dict(arrowstyle=\"->\", color='k', lw=1))       \n",
    "plt.xlabel('log2(Inflammatory group/Healthy group)')\n",
    "plt.ylabel('-log10(p-value)')\n",
    "plt.title('BIOMASS_maintenance')\n",
    "plt.axhline(-np.log10(0.05), color='black', linestyle='--')\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "\n",
    "def create_legend_entry(label, size, color):\n",
    "    line = Line2D([0], [0], marker='o', color='w', label=label, markersize=np.sqrt(size), markerfacecolor=color)\n",
    "    arrow = FancyArrowPatch((0, 0), (1, 0), mutation_scale=10, color=color)\n",
    "    return line, arrow\n",
    "\n",
    "# Create legend entries\n",
    "small_line, small_arrow = create_legend_entry('', 50, 'blue')\n",
    "medium_line, medium_arrow = create_legend_entry('', 100, 'blue')\n",
    "large_line, large_arrow = create_legend_entry('', 150, 'blue')\n",
    "Super_large_line, Super_large_arrow = create_legend_entry('', 200, 'blue')\n",
    "\n",
    "legend_elements = [small_line, medium_line, large_line, Super_large_line]\n",
    "plt.legend(handles=legend_elements, title='Effect Size', bbox_to_anchor=(1.2, 1.04), loc='upper right', frameon=False)\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.savefig('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_UC/Figure/UC_BIOMASS_maintenance', dpi=900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CD study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD healthy\n",
    "# Run FVA with context-specific reconstructions of healthy samples in the CD study\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FAV_per_sample/model_imat/Healthy/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FAV_per_sample/model_imat/Healthy/'\n",
    "for i in files_path:\n",
    "    model_path = folder + i\n",
    "    print(model_path)\n",
    "    model = cobra.io.load_matlab_model(model_path)\n",
    "    model.objective = ['ACSm', 'FACOAL40im', 'BIOMASS_maintenance']\n",
    "    model.solver = 'cplex'\n",
    "    print(model.objective.expression)\n",
    "    fva_output = flux_variability_analysis(model)\n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FAV_per_sample/FVA_outputs/'\n",
    "    file_name = i.split('.mat')[0]\n",
    "    save_path = save_path + file_name + '.csv'\n",
    "    fva_output.to_csv(save_path)\n",
    "    print('------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD Inflammatory\n",
    "# Run FVA with context-specific reconstructions of inflammatory samples in the CD study\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FAV_per_sample/model_imat/Inflamed/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FAV_per_sample/model_imat/Inflamed/'\n",
    "for i in files_path:\n",
    "    model_path = folder + i\n",
    "    print(model_path)\n",
    "    model = cobra.io.load_matlab_model(model_path)\n",
    "    model.objective = ['ACSm', 'FACOAL40im', 'BIOMASS_maintenance']\n",
    "    model.solver = 'cplex'\n",
    "    print(model.objective.expression)\n",
    "    fva_output = flux_variability_analysis(model)\n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FAV_per_sample/FVA_outputs/'\n",
    "    file_name = i.split('.mat')[0]\n",
    "    save_path = save_path + file_name + '.csv'\n",
    "    fva_output.to_csv(save_path)\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge maximum flux of the FVA outputs above\n",
    "reactions = []\n",
    "CD189 = {}\n",
    "CD299 = {}\n",
    "CD364 = {}\n",
    "HT206 = {}\n",
    "HT214 = {}\n",
    "HT216 = {}\n",
    "HT217 = {}\n",
    "CD189_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/CD189.csv')\n",
    "for i in range(len(CD189_fva)):\n",
    "    rxn = CD189_fva.iloc[i,0]\n",
    "    maximum = CD189_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    CD189[rxn] = maximum\n",
    "\n",
    "CD299_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/CD299.csv')\n",
    "for i in range(len(CD299_fva)):\n",
    "    rxn = CD299_fva.iloc[i,0]\n",
    "    maximum = CD299_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    CD299[rxn] = maximum\n",
    "\n",
    "CD364_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/CD364.csv')\n",
    "for i in range(len(CD364_fva)):\n",
    "    rxn = CD364_fva.iloc[i,0]\n",
    "    maximum = CD364_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    CD364[rxn] = maximum\n",
    "\n",
    "HT206_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/HT206.csv')\n",
    "for i in range(len(HT206_fva)):\n",
    "    rxn = HT206_fva.iloc[i,0]\n",
    "    maximum = HT206_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    HT206[rxn] = maximum\n",
    "\n",
    "HT214_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/HT214.csv')\n",
    "for i in range(len(HT214_fva)):\n",
    "    rxn = HT214_fva.iloc[i,0]\n",
    "    maximum = HT214_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    HT214[rxn] = maximum\n",
    "\n",
    "\n",
    "HT216_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/HT216.csv')\n",
    "for i in range(len(HT216_fva)):\n",
    "    rxn = HT216_fva.iloc[i,0]\n",
    "    maximum = HT216_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    HT216[rxn] = maximum\n",
    "\n",
    "HT217_fva = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FVA_outputs/HT217.csv')\n",
    "for i in range(len(HT217_fva)):\n",
    "    rxn = HT217_fva.iloc[i,0]\n",
    "    maximum = HT217_fva.iloc[i,2]\n",
    "    reactions.append(rxn)\n",
    "    HT217[rxn] = maximum\n",
    "\n",
    "\n",
    "reaction_deduplicated = list(set(reactions))\n",
    "len(reaction_deduplicated)\n",
    "\n",
    "workbook =xlsxwriter.Workbook('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/Results_analysis/FVA_mergedAll.xlsx', {\"nan_inf_to_errors\": True})\n",
    "worksheet = workbook.add_worksheet()\n",
    "worksheet.write(0,1,'CD189')\n",
    "worksheet.write(0,2,'CD299')\n",
    "worksheet.write(0,3,'CD364')\n",
    "worksheet.write(0,4,'HT206')\n",
    "worksheet.write(0,5,'HT214')\n",
    "worksheet.write(0,6,'HT216')\n",
    "worksheet.write(0,7,'HT217')\n",
    "reaction_CD189 = list(CD189.keys())\n",
    "reaction_CD299 = list(CD299.keys())\n",
    "reaction_CD364 = list(CD364.keys())\n",
    "reaction_HT206 = list(HT206.keys())\n",
    "reaction_HT214 = list(HT214.keys())\n",
    "reaction_HT216 = list(HT216.keys())\n",
    "reaction_HT217 = list(HT217.keys())\n",
    "for i in range(len(reaction_deduplicated)):\n",
    "    reaction = reaction_deduplicated[i]\n",
    "    worksheet.write(i+1, 0, reaction)\n",
    "    if reaction in reaction_CD189:\n",
    "        value = CD189[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 1, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 1, value)\n",
    "\n",
    "\n",
    "    if reaction in reaction_CD299:\n",
    "        value = CD299[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 2, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 2, value)\n",
    "\n",
    "\n",
    "    if reaction in reaction_CD364:\n",
    "        value = CD364[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 3, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 3, value)\n",
    "\n",
    "    if reaction in reaction_HT206:\n",
    "        value = HT206[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 4, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 4, value)\n",
    "\n",
    "    if reaction in reaction_HT214:\n",
    "        value = HT214[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 5, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 5, value)\n",
    "\n",
    "    if reaction in reaction_HT216:\n",
    "        value = HT216[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 6, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 6, value)\n",
    "\n",
    "    if reaction in reaction_HT217:\n",
    "        value = HT217[reaction]\n",
    "        print(value)\n",
    "        worksheet.write(i+1, 7, value)\n",
    "    else:\n",
    "        value = np.nan\n",
    "        print('NONE')\n",
    "        worksheet.write(i+1, 7, value)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD T-test \n",
    "CD_data = pd.read_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/Results_analysis/FVA_mergedAll.xlsx', index_col=0)\n",
    "p_val = []\n",
    "for i in range(len(CD_data)):\n",
    "    rxn_id = CD_data.index[i]\n",
    "    rxn_fluxes = CD_data.loc[rxn_id].tolist()\n",
    "    ifla_flux = rxn_fluxes[0:3]\n",
    "    ht_flux  = rxn_fluxes[3:]\n",
    "    try:\n",
    "        t_statistic, p_value = ttest_ind(ifla_flux, ht_flux)\n",
    "        p_val.append(p_value)\n",
    "    except:\n",
    "        p_val.append(np.nan)\n",
    "\n",
    "CD_data['p_value'] = p_val\n",
    "CD_data.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/Results_analysis/CD_t_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Flux sampling with all context-specific reconstructions in the CD study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD_folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/mode_imat/'\n",
    "\n",
    "for i in ['Healthy', 'Inflamed']:\n",
    "    folder =  CD_folder + i\n",
    "    print(folder)\n",
    "    file_names = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    print(file_names)\n",
    "\n",
    "    for i in range(len(file_names)):\n",
    "        print(i)\n",
    "        filename  = file_names[i]\n",
    "        print(filename)\n",
    "        file_path = folder + '/' + filename\n",
    "        model = load_matlab_model(file_path)\n",
    "        #model.objective = ['ACSm', 'FACOAL40im', 'BIOMASS_maintenance']\n",
    "\n",
    "        try:\n",
    "            achr = ACHRSampler(model, thinning=10)\n",
    "            s1 = achr.sample(100)\n",
    "            save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/CD/'\n",
    "            save_file_name = filename.split('.xml')[0]\n",
    "            save_file = save_path + save_file_name + '.csv'\n",
    "            s1.to_csv(save_file)\n",
    "        except:\n",
    "            print('cannnot obtain sampling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_lists_to_same_length(data, pad_value=np.nan):\n",
    "    max_length = max(len(lst) for lst in data.values())\n",
    "    for key, lst in data.items():\n",
    "        if len(lst) < max_length:\n",
    "            data[key].extend([pad_value] * (max_length - len(lst)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined fluxes from each group of CD\n",
    "cd_flux_files = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/CD')\n",
    "cd_flux_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/CD/'\n",
    "\n",
    "# CD_inflamed \n",
    "inflam_dict = {}\n",
    "for i in cd_flux_files:\n",
    "    if i.startswith('CD'):\n",
    "        file_path = cd_flux_path + '/' + i\n",
    "        fluxes_data = pd.read_csv(file_path, index_col=0)\n",
    "        rxn_list = fluxes_data.columns.to_list()\n",
    "        for i in rxn_list:\n",
    "            rxn = i\n",
    "            rxn_flux = fluxes_data[rxn].to_list()\n",
    "            if rxn not in inflam_dict.keys():\n",
    "                inflam_dict[rxn] = rxn_flux\n",
    "            else:\n",
    "                ori_flux = inflam_dict[rxn]\n",
    "                combined_flux = ori_flux + rxn_flux\n",
    "                inflam_dict[rxn] = combined_flux\n",
    "        inflam_dict = pad_lists_to_same_length(inflam_dict)\n",
    "df_inflam = pd.DataFrame(inflam_dict)\n",
    "df_inflam.to_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output_updated/CD_inflam_combined.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "health_dict = {}\n",
    "for i in cd_flux_files:\n",
    "    if i.startswith('HT'):\n",
    "        file_path = cd_flux_path + '/' + i\n",
    "        fluxes_data = pd.read_csv(file_path, index_col=0)\n",
    "        rxn_list = fluxes_data.columns.to_list()\n",
    "        for i in rxn_list:\n",
    "            rxn = i\n",
    "            rxn_flux = fluxes_data[rxn].to_list()\n",
    "            if rxn not in health_dict.keys():\n",
    "                health_dict[rxn] = rxn_flux\n",
    "            else:\n",
    "                ori_flux = health_dict[rxn]\n",
    "                combined_flux = ori_flux + rxn_flux\n",
    "                health_dict[rxn] = combined_flux\n",
    "        health_dict = pad_lists_to_same_length(health_dict)\n",
    "df_HT = pd.DataFrame(health_dict)\n",
    "df_HT.to_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output_updated/CD_HT_combined.csv')\n",
    "\n",
    "\n",
    "cd_inflammation = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/CD_inflam_combined.csv', index_col=0)\n",
    "cd_health = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/CD_HT_combined.csv', index_col=0)\n",
    "\n",
    "workbook = xlsxwriter.Workbook('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/CD_combinedFlux_comparsion.xlsx')\n",
    "sheet1 = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "sheet1.write(0, 0, 'CD_inflammation_vs_health')\n",
    "sheet1.write(1, 0, 'Reactions')\n",
    "sheet1.write(1, 1, 'Subsystem')\n",
    "sheet1.write(1, 2, 'Flux_CD')\n",
    "sheet1.write(1, 3, 'Flux_HT')\n",
    "sheet1.write(1, 4, 'P-value')\n",
    "inflam_rxns = cd_inflammation.columns.to_list()\n",
    "health_rxns = cd_health.columns.to_list()\n",
    "overlapped_rxn = list(set(inflam_rxns).intersection(health_rxns))\n",
    "\n",
    "row_index = 2\n",
    "for rxn in overlapped_rxn:\n",
    "    #print(rxn)\n",
    "    sheet1.write(row_index, 0, rxn)\n",
    "    \n",
    "    inflam_fluxes = cd_inflammation[rxn].to_list()\n",
    "    inflam_fluxes = [x for x in inflam_fluxes if not math.isnan(x)]\n",
    "    health_fluxes = cd_health[rxn].to_list()\n",
    "    health_fluxes = [x for x in health_fluxes if not math.isnan(x)]\n",
    "    inflam_fluxes_mean = mean(inflam_fluxes)\n",
    "    health_fluxes_mean = mean(health_fluxes)\n",
    "    sheet1.write(row_index, 2, inflam_fluxes_mean)\n",
    "    sheet1.write(row_index, 3, health_fluxes_mean)\n",
    "    t_statistic, p_value = ttest_ind(inflam_fluxes, health_fluxes)\n",
    "    sheet1.write(row_index, 4, p_value)\n",
    "    row_index +=1\n",
    "\n",
    "\n",
    "\n",
    "workbook.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build combined flux distribution plot of CD\n",
    "sampling_input = pd.read_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Flux sampling/DistributePlot/Flux sampling inputs.xlsx')\n",
    "Nuceltide_list = sampling_input['Nucleotide interconversion'].to_list()\n",
    "fatty_acid_list = sampling_input['Fatty acid metabolism'].to_list()\n",
    "Purine_list = sampling_input['Purine metabolism'].to_list()\n",
    "\n",
    "\n",
    "CD_inflam_fluxes = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/CD_HT_combined.csv', index_col=0)\n",
    "CD_health_fluxes = pd.read_csv('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/Flux sampling/Output/CD_inflam_combined.csv', index_col=0)\n",
    "\n",
    "save_folder_fatty = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Flux sampling/DistributePlot_0525_2024/Fatty acid/'\n",
    "\n",
    "for i in fatty_acid_list:\n",
    "    reaction = i\n",
    "    print(reaction)\n",
    "    try:\n",
    "        CD_inflam_data = CD_inflam_fluxes[reaction].to_list()\n",
    "        CD_inflam_data = [x for x in CD_inflam_data if not math.isnan(x)]\n",
    "        CD_health_data = CD_health_fluxes[reaction].to_list()\n",
    "        CD_health_data = [x for x in CD_health_data if not math.isnan(x)]\n",
    "\n",
    "        # Sample data\n",
    "        data1 = CD_inflam_data\n",
    "        data2 = CD_health_data\n",
    "\n",
    "        # Create distribution plot for data1 and data2\n",
    "        sns.histplot(data1, kde=True, color='red', label='Inflammatory group', alpha=0.5)\n",
    "        sns.histplot(data2, kde=True, color='blue', label='Healthy group', alpha=0.5)\n",
    "\n",
    "        plt.xlabel('Flux value (mmol/gDW/h)')\n",
    "        plt.ylabel('Density')\n",
    "        Plot_title = 'CD study: ' + reaction\n",
    "        plt.title(Plot_title)\n",
    "        plt.legend()\n",
    "        save_path = save_folder_fatty + 'CD_' + reaction + '.png'\n",
    "        plt.savefig(save_path,dpi=600)\n",
    "        plt.show()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single gene knockout simulation in CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icolon = read_sbml_model('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Draft_reconstructions/Draft_reconstruction_consensus/icolonoEpithelium.xml')\n",
    "reactions_all = ['BIOMASS_maintenance', 'ACSm', 'FACOAL40im', \n",
    "                 'HACD1m',\n",
    "                 'ECOAH1m',\n",
    "                 '5HOXINDACTOX',\n",
    "                 'ECOAH1x',\n",
    "                 'HACD1x',\n",
    "                 '3HKYNAKGAT',\n",
    "                 '5HOXINOXDA',\n",
    "                 'RE2349C',\n",
    "                 'r0647',\n",
    "                 'ACACT1m']\n",
    "merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "merged_df.index = merged_df['reaction_id']\n",
    "\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/model_imat/Healthy/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/model_imat/Healthy/'\n",
    "print(files_path)\n",
    "\n",
    "for i in range(len(files_path)):\n",
    "    print(i)\n",
    "    file_name = files_path[i]\n",
    "    print(file_name)\n",
    "    merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "    merged_df.index = merged_df['reaction_id']\n",
    "    \n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/' + file_name + '_knock.xlsx'\n",
    "\n",
    "    \n",
    "    model_path = folder + file_name\n",
    "    model = load_matlab_model(model_path)\n",
    "    reaction = [i.id for i in model.reactions]\n",
    "    reactions_all_filter = list(set(reactions_all)&set(reaction))\n",
    "    model.solver = 'cplex'\n",
    "    print(i)\n",
    "    index = 0\n",
    "    for i in model.genes:\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        index +=1 \n",
    "        gene_id = i.id\n",
    "        \n",
    "        model_copy = model.copy()\n",
    "        model_copy.genes.get_by_id(gene_id).knock_out()\n",
    "        fva = flux_variability_analysis(model_copy, reactions_all_filter, processes = 6)\n",
    "        fva = fva.drop(columns=['minimum'])\n",
    "        fva.rename(columns={'maximum': gene_id}, inplace=True)\n",
    "        merged_df = pd.merge(merged_df,fva, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "    merged_df.to_excel(save_path)\n",
    "    print('complete knockout:', file_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colon = read_sbml_model('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Draft_reconstructions/Draft_reconstruction_consensus/icolonoEpithelium.xml')\n",
    "reactions_all = ['BIOMASS_maintenance', 'ACSm', 'FACOAL40im', \n",
    "                 'HACD1m',\n",
    "                 'ECOAH1m',\n",
    "                 '5HOXINDACTOX',\n",
    "                 'ECOAH1x',\n",
    "                 'HACD1x',\n",
    "                 '3HKYNAKGAT',\n",
    "                 '5HOXINOXDA',\n",
    "                 'RE2349C',\n",
    "                 'r0647',\n",
    "                 'ACACT1m']\n",
    "merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "merged_df.index = merged_df['reaction_id']\n",
    "\n",
    "files_path = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/model_imat/Inflamed/')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/model_imat/Inflamed/'\n",
    "print(files_path)\n",
    "\n",
    "for i in range(len(files_path)):\n",
    "    print(i)\n",
    "    file_name = files_path[i]\n",
    "    print(file_name)\n",
    "    merged_df = pd.DataFrame({'reaction_id': reactions_all})\n",
    "    merged_df.index = merged_df['reaction_id']\n",
    "    \n",
    "    save_path = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/' + file_name + '_knock.xlsx'\n",
    "\n",
    "    \n",
    "    model_path = folder + file_name\n",
    "    model = load_matlab_model(model_path)\n",
    "    reaction = [i.id for i in model.reactions]\n",
    "    reactions_all_filter = list(set(reactions_all)&set(reaction))\n",
    "    model.solver = 'cplex'\n",
    "    print(i)\n",
    "    index = 0\n",
    "    for i in model.genes:\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        index +=1 \n",
    "        gene_id = i.id\n",
    "        \n",
    "        model_copy = model.copy()\n",
    "        model_copy.genes.get_by_id(gene_id).knock_out()\n",
    "        fva = flux_variability_analysis(model_copy, reactions_all_filter, processes = 9)\n",
    "        fva = fva.drop(columns=['minimum'])\n",
    "        fva.rename(columns={'maximum': gene_id}, inplace=True)\n",
    "        merged_df = pd.merge(merged_df,fva, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "    merged_df.to_excel(save_path)\n",
    "    print(\"knock completed:\", file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "reactions_all = [i.id for i in icolon.genes]\n",
    "merged_df = pd.DataFrame({'': reactions_all})\n",
    "merged_df.index = merged_df['']\n",
    "                             \n",
    "merged_biomass = merged_df['']\n",
    "merged_acsm = merged_df['']\n",
    "merge_FACOAL40im = merged_df['']\n",
    "merge_ACACT1m = merged_df['']\n",
    "merge_ECOAH1m = merged_df['']\n",
    "merge_5HOXINOXDA = merged_df['']\n",
    "merge_5HOXINDACTOX = merged_df['']\n",
    "merge_3HKYNAKGAT = merged_df['']\n",
    "\n",
    "\n",
    "files = os.listdir('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD')\n",
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/'\n",
    "files.remove('processed')\n",
    "files.remove('plot_dada')\n",
    "\n",
    "\n",
    "files.sort()\n",
    "\n",
    "for i in files:\n",
    "    print(i)\n",
    "    sample_id = i.split('.mat_knock.xlsx')[0]\n",
    "    print(sample_id)\n",
    "    file_path = folder + i\n",
    "    df_ko = pd.read_excel(file_path)\n",
    "    df_ko.index = df_ko['reaction_id']\n",
    "\n",
    "    selected_rxn = ['BIOMASS_maintenance', \n",
    "                    'ACSm', \n",
    "                    'FACOAL40im', \n",
    "                    'ACACT1m', \n",
    "                    'ECOAH1m', \n",
    "                    '5HOXINOXDA', \n",
    "                    '5HOXINDACTOX', \n",
    "                    '3HKYNAKGAT']\n",
    "\n",
    "    df_ko = df_ko.loc[selected_rxn]\n",
    "    \n",
    "\n",
    "    col1 = sample_id + '_BIOMASS_maintenance'\n",
    "    col2 = sample_id + '_ACSm'\n",
    "    col3 = sample_id + '_FACOAL40im'\n",
    "    col4 = sample_id + '_ACACT1m'\n",
    "    col5 = sample_id + '_ECOAH1m'\n",
    "    col6 = sample_id + '_5HOXINOXDA'\n",
    "    col7 = sample_id + '_5HOXINDACTOX'\n",
    "    col8 = sample_id + '_3HKYNAKGAT'\n",
    "\n",
    "    df_ko_t = df_ko.T\n",
    "    df_ko_t.columns =[col1, col2, col3, col4, col5, col6, col7, col8]\n",
    "    df_ko_t = df_ko_t.iloc[2:]\n",
    "\n",
    "\n",
    "    wt_df_folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Case_Studies/GSE164985/FVA_per_sample/FAV_outputs/'\n",
    "    wt_df_folder_path = wt_df_folder  + sample_id + '.csv'\n",
    "    wt_df = pd.read_csv(wt_df_folder_path, index_col=0)\n",
    "   \n",
    "    wt_BIOMASS = wt_df.loc['BIOMASS_maintenance', 'maximum']\n",
    "    if wt_BIOMASS == 0:\n",
    "        wt_BIOMASS = 1e-8\n",
    "        print('set wt_BIOMASS as 1e-8')\n",
    "    else:\n",
    "        print(wt_BIOMASS)\n",
    "\n",
    "    wt_acsm = wt_df.loc['ACSm', 'maximum']\n",
    "    if wt_acsm == 0:\n",
    "        wt_acsm = 1e-8\n",
    "        print('set wt_acsm as 1e-8')\n",
    "    else:\n",
    "        print(wt_acsm)\n",
    "   \n",
    "    wt_FACOAL40im = wt_df.loc['FACOAL40im', 'maximum']\n",
    "    if wt_FACOAL40im == 0:\n",
    "        wt_FACOAL40im = 1e-8\n",
    "        print('set wt_FACOAL40im as 1e-8')\n",
    "    else:\n",
    "        print(wt_FACOAL40im)\n",
    "\n",
    "    try:\n",
    "        wt_ACACT1m = wt_df.loc['ACACT1m', 'maximum']\n",
    "        if wt_ACACT1m == 0:\n",
    "            wt_ACACT1m = 1e-8\n",
    "            print('set wt_ACACT1m as 1e-8')\n",
    "        else:\n",
    "            print(wt_ACACT1m)\n",
    "    except:\n",
    "        wt_ACACT1m = 1e-8\n",
    "        print('set wt_ACACT1m as 1e-8')\n",
    "\n",
    "    try:\n",
    "        wt_ECOAH1m = wt_df.loc['ECOAH1m', 'maximum']\n",
    "        if wt_ECOAH1m == 0:\n",
    "            wt_ECOAH1m = 1e-8\n",
    "            print('set wt_ECOAH1m as 1e-8')\n",
    "        else:\n",
    "            print(wt_ECOAH1m)\n",
    "    except:\n",
    "        wt_ECOAH1m = 1e-8\n",
    "        print('set wt_ECOAH1m as 1e-8')\n",
    "\n",
    "\n",
    "    try:\n",
    "        wt_5HOXINDACTOX = wt_df.loc['5HOXINDACTOX', 'maximum']\n",
    "        if wt_5HOXINDACTOX == 0:\n",
    "            wt_5HOXINDACTOX = 1e-8\n",
    "            print('set wt_5HOXINDACTOX as 1e-8')\n",
    "        else:\n",
    "            print(wt_5HOXINDACTOX)\n",
    "    except:\n",
    "        wt_5HOXINDACTOX = 1e-8\n",
    "        print('set wt_5HOXINDACTOX as 1e-8')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        wt_5HOXINOXDA = wt_df.loc['5HOXINOXDA', 'maximum']\n",
    "        if wt_5HOXINOXDA == 0:\n",
    "            wt_5HOXINOXDA = 1e-8\n",
    "            print('set wt_5HOXINOXDA as 1e-8')\n",
    "        else:\n",
    "            print(wt_5HOXINOXDA)\n",
    "    except:\n",
    "        wt_5HOXINOXDA = 1e-8\n",
    "        print('set wt_5HOXINOXDA as 1e-8')\n",
    "\n",
    "\n",
    "    try:\n",
    "        wt_3HKYNAKGAT = wt_df.loc['3HKYNAKGAT', 'maximum']\n",
    "        if wt_3HKYNAKGAT == 0:\n",
    "            wt_3HKYNAKGAT = 1e-8\n",
    "            print('set wt_3HKYNAKGAT as 1e-8')\n",
    "        else:\n",
    "            print(wt_3HKYNAKGAT)\n",
    "    except:\n",
    "        wt_3HKYNAKGAT = 1e-8\n",
    "        print('set wt_3HKYNAKGAT as 1e-8')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    BIOMASS = df_ko_t.iloc[:, 0:1]\n",
    "    BIOMASS = (wt_BIOMASS-BIOMASS)/wt_BIOMASS\n",
    "    merged_biomass = pd.merge(merged_biomass, BIOMASS, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    acsm = df_ko_t.iloc[:, 1:2]\n",
    "    acsm = (wt_acsm-acsm)/wt_acsm\n",
    "    merged_acsm = pd.merge(merged_acsm, acsm, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    FACOAL40im = df_ko_t.iloc[:, 2:3]\n",
    "    FACOAL40im = (wt_FACOAL40im-FACOAL40im)/wt_FACOAL40im\n",
    "    merge_FACOAL40im = pd.merge(merge_FACOAL40im, FACOAL40im, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    ACACT1m = df_ko_t.iloc[:, 3:4]\n",
    "    ACACT1m = (wt_ACACT1m-ACACT1m)/wt_ACACT1m\n",
    "    merge_ACACT1m = pd.merge(merge_ACACT1m, ACACT1m, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    ECOAH1m = df_ko_t.iloc[:, 4:5]\n",
    "    ECOAH1m = (wt_ECOAH1m-ECOAH1m)/wt_ECOAH1m\n",
    "    merge_ECOAH1m = pd.merge(merge_ECOAH1m, ECOAH1m, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    _5HOXINOXDA = df_ko_t.iloc[:, 5:6]\n",
    "    _5HOXINOXDA = (wt_5HOXINOXDA-_5HOXINOXDA)/wt_5HOXINOXDA\n",
    "    merge_5HOXINOXDA = pd.merge(merge_5HOXINOXDA, _5HOXINOXDA, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    _5HOXINDACTOX = df_ko_t.iloc[:, 6:7]\n",
    "    _5HOXINDACTOX = (wt_5HOXINDACTOX-_5HOXINDACTOX)/wt_5HOXINDACTOX\n",
    "    merge_5HOXINDACTOX = pd.merge(merge_5HOXINDACTOX, _5HOXINDACTOX, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    _3HKYNAKGAT = df_ko_t.iloc[:, 7:8]\n",
    "    _3HKYNAKGAT = (wt_3HKYNAKGAT-_3HKYNAKGAT)/wt_3HKYNAKGAT\n",
    "    merge_3HKYNAKGAT = pd.merge(merge_3HKYNAKGAT, _3HKYNAKGAT, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    \n",
    "\n",
    "merged_biomass = merged_biomass.drop(merged_biomass.columns[0], axis=1)\n",
    "merged_acsm = merged_acsm.drop(merged_acsm.columns[0], axis=1)\n",
    "merge_FACOAL40im = merge_FACOAL40im.drop(merge_FACOAL40im.columns[0], axis=1)\n",
    "merge_ACACT1m = merge_ACACT1m.drop(merge_ACACT1m.columns[0], axis=1)\n",
    "merge_ECOAH1m = merge_ECOAH1m.drop(merge_ECOAH1m.columns[0], axis=1)\n",
    "merge_5HOXINOXDA = merge_5HOXINOXDA.drop(merge_5HOXINOXDA.columns[0], axis=1)\n",
    "merge_5HOXINDACTOX = merge_5HOXINDACTOX.drop(merge_5HOXINDACTOX.columns[0], axis=1)\n",
    "merge_3HKYNAKGAT = merge_3HKYNAKGAT.drop(merge_3HKYNAKGAT.columns[0], axis=1)   \n",
    "    \n",
    "\n",
    "\n",
    "# change gene names\n",
    "new_row_names  = {}\n",
    "for i in df_ko_t.index:\n",
    "    new_row_names[i] = icolon.genes.get_by_id(i).name\n",
    "\n",
    "merged_biomass = merged_biomass.rename(index=new_row_names)\n",
    "merged_biomass.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_BIOMASS.xlsx')\n",
    "\n",
    "merged_acsm = merged_acsm.rename(index=new_row_names)\n",
    "merged_acsm.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_ACSm.xlsx')\n",
    "\n",
    "merge_FACOAL40im = merge_FACOAL40im.rename(index=new_row_names)\n",
    "merge_FACOAL40im.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_FACOAL40im.xlsx')\n",
    "\n",
    "merge_ACACT1m = merge_ACACT1m.rename(index=new_row_names)\n",
    "merge_ACACT1m.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_ACACT1m.xlsx')\n",
    "\n",
    "merge_ECOAH1m = merge_ECOAH1m.rename(index=new_row_names)\n",
    "merge_ECOAH1m.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_ECOAH1m.xlsx')\n",
    "\n",
    "merge_5HOXINOXDA = merge_5HOXINOXDA.rename(index=new_row_names)\n",
    "merge_5HOXINOXDA.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_5HOXINOXDA.xlsx')\n",
    "\n",
    "merge_5HOXINDACTOX = merge_5HOXINDACTOX.rename(index=new_row_names)\n",
    "merge_5HOXINDACTOX.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_5HOXINDACTOX.xlsx')\n",
    "\n",
    "merge_3HKYNAKGAT = merge_3HKYNAKGAT.rename(index=new_row_names)\n",
    "merge_3HKYNAKGAT.to_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/CD_3HKYNAKGAT.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/processed/'\n",
    "files = os.listdir(folder)\n",
    "\n",
    "for i in files:\n",
    "    file_path = folder + i\n",
    "    print(i)\n",
    "    df = pd.read_excel(file_path, index_col=0)\n",
    "    df.sort_values(by=df.columns.tolist(), ascending=True, inplace=True)\n",
    "    cd_mean  = df.iloc[:, :3].mean(axis=1)\n",
    "    ht_mean  = df.iloc[:, 3:7].mean(axis=1)\n",
    "    all_mean = df.iloc[:, 0:7].mean(axis=1)\n",
    "    ratio = abs(cd_mean/ht_mean)\n",
    "    try:\n",
    "        ratio_log2 = ratio.apply(lambda x: math.log2(x))\n",
    "    except:\n",
    "        cd_mean  = df.iloc[:, :3].mean(axis=1)\n",
    "        cd_mean = cd_mean.replace(0, 1e-8)\n",
    "        ht_mean  = df.iloc[:, 3:7].mean(axis=1)\n",
    "        all_mean = df.iloc[:, 0:7].mean(axis=1)\n",
    "        ratio = abs(cd_mean/ht_mean)\n",
    "        ratio_log2 = ratio.apply(lambda x: math.log2(x))\n",
    "\n",
    "    ratio_log2 = ratio_log2.to_frame()\n",
    "    \n",
    "    # t-test\n",
    "    cd = df.iloc[:, :3]\n",
    "    ht = df.iloc[:, 3:7]\n",
    "    t_statistic, p_values = ttest_ind(cd, ht, axis=1, nan_policy='omit')\n",
    "\n",
    "    geneID = cd.index\n",
    "    geneID = geneID.to_list()\n",
    "    p_values = list(p_values)\n",
    "    ttest_results = pd.DataFrame({'GeneID':geneID, 'p-valve': p_values})\n",
    "    ttest_results.index = ttest_results['GeneID']\n",
    "    ttest_results = ttest_results.drop('GeneID', axis=1)\n",
    "    \n",
    "    ratio_log2.rename(columns={ratio_log2.columns[0]: 'log2(CD/WT)'}, inplace=True)\n",
    "    ratio_log2['all mean'] = all_mean\n",
    "    volcano_data = pd.merge(ratio_log2, ttest_results, left_index=True, right_index=True, how='left')\n",
    "    volcanoPlot_data_save = '/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/plot_dada/' + i\n",
    "    print(volcanoPlot_data_save)\n",
    "    volcano_data.to_excel(volcanoPlot_data_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build  volcano plot of CD study\n",
    "volcano_data = pd.read_excel('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/plot_dada/CD_BIOMASS.xlsx', index_col=0)\n",
    "\n",
    "log_fold_change = volcano_data['log2(CD/WT)']\n",
    "p_values = volcano_data['p-valve']\n",
    "p_values = -np.log10(p_values)\n",
    "all_mean = volcano_data['all mean']\n",
    "gene_id = volcano_data.index.to_list()\n",
    "threshold = -np.log10(0.05)\n",
    "\n",
    "sizes = np.linspace(1, 250, len(all_mean))\n",
    "colors = ['red' if fc > 0 else 'blue' for fc in log_fold_change]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(log_fold_change, p_values, s=sizes, c=colors, alpha=0.5)\n",
    "\n",
    "text = []\n",
    "font_props = {'family': 'monospace', 'size': 8, 'weight': 'bold'}\n",
    "for x, y, l in zip(log_fold_change, p_values, gene_id):\n",
    "    if y > -np.log10(0.05):\n",
    "        text.append(plt.text(x, y, l, size=10, ha='center', va='center', fontdict=font_props))\n",
    "\n",
    "adjust_text(text, expand=(5, 7),arrowprops=dict(arrowstyle=\"->\", color='k', lw=1))       \n",
    "plt.xlabel('log2(Inflammatory group/Healthy group)')\n",
    "plt.ylabel('-log10(p-value)')\n",
    "plt.title('BIOMASS_maintenance')\n",
    "plt.axhline(-np.log10(0.05), color='black', linestyle='--')\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "\n",
    "def create_legend_entry(label, size, color):\n",
    "    line = Line2D([0], [0], marker='o', color='w', label=label, markersize=np.sqrt(size), markerfacecolor=color)\n",
    "    arrow = FancyArrowPatch((0, 0), (1, 0), mutation_scale=10, color=color)\n",
    "    return line, arrow\n",
    "\n",
    "# Create legend entries\n",
    "small_line, small_arrow = create_legend_entry('', 50, 'blue')\n",
    "medium_line, medium_arrow = create_legend_entry('', 100, 'blue')\n",
    "large_line, large_arrow = create_legend_entry('', 150, 'blue')\n",
    "Super_large_line, Super_large_arrow = create_legend_entry('', 200, 'blue')\n",
    "\n",
    "legend_elements = [small_line, medium_line, large_line, Super_large_line]\n",
    "plt.legend(handles=legend_elements, title='Effect Size', bbox_to_anchor=(1.2, 1.04), loc='upper right', frameon=False)\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.savefig('/depot/pbaloni/data/Lab_members/Boyu_Jiang/Cybergut/Manuscript/Knockout/Knockout_simulation_CD/Figure/CD_BIOMASS_maintenance', dpi=900)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
